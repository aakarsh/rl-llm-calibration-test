
@article{noauthor_as_nodate,
	title = {Do {As} {I} {Can}, {Not} {As} {I} {Say}.  {Grounding} {Language} in {Robot} {Affordances} - {Reinforcement} {Learning} for {Large} {Language} {Models}   {Winter} 2023},
	language = {en},
	file = {W23_RL_LLM_Presentation-FINAL.pdf:files/165/W23_RL_LLM_Presentation-FINAL.pdf:application/pdf},
}

@article{levine_mdoamchaiinnes_nodate,
	title = {Mdoamchaiinnes lreaanrgniinnggfsroysmtecmosmhpauvteermvaissiotenretodsapbereecahdtrhecoofgcnhiatilolennagnindg…problems in},
	language = {en},
	author = {Levine, Sergey},
	file = {Understanding the World Through Action_ RL as a Foundation for Scalable Self-Supervised Learning.pdf:files/166/Understanding the World Through Action_ RL as a Foundation for Scalable Self-Supervised Learning.pdf:application/pdf},
}

@article{li_competition-level_2022,
	title = {Competition-{Level} {Code} {Generation} with {AlphaCode}},
	volume = {378},
	issn = {0036-8075, 1095-9203},
	url = {http://arxiv.org/abs/2203.07814},
	doi = {10.1126/science.abq1158},
	abstract = {Programming is a powerful and ubiquitous problem-solving tool. Developing systems that can assist programmers or even generate programs independently could make programming more productive and accessible, yet so far incorporating innovations in AI has proven challenging. Recent large-scale language models have demonstrated an impressive ability to generate code, and are now able to complete simple programming tasks. However, these models still perform poorly when evaluated on more complex, unseen problems that require problem-solving skills beyond simply translating instructions into code. For example, competitive programming problems which require an understanding of algorithms and complex natural language remain extremely challenging. To address this gap, we introduce AlphaCode, a system for code generation that can create novel solutions to these problems that require deeper reasoning. In simulated evaluations on recent programming competitions on the Codeforces platform, AlphaCode achieved on average a ranking of top 54.3\% in competitions with more than 5,000 participants. We found that three key components were critical to achieve good and reliable performance: (1) an extensive and clean competitive programming dataset for training and evaluation, (2) large and efficient-to-sample transformer-based architectures, and (3) large-scale model sampling to explore the search space, followed by filtering based on program behavior to a small set of submissions.},
	language = {en},
	number = {6624},
	urldate = {2024-01-31},
	journal = {Science},
	author = {Li, Yujia and Choi, David and Chung, Junyoung and Kushman, Nate and Schrittwieser, Julian and Leblond, Rémi and Eccles, Tom and Keeling, James and Gimeno, Felix and Lago, Agustin Dal and Hubert, Thomas and Choy, Peter and d'Autume, Cyprien de Masson and Babuschkin, Igor and Chen, Xinyun and Huang, Po-Sen and Welbl, Johannes and Gowal, Sven and Cherepanov, Alexey and Molloy, James and Mankowitz, Daniel J. and Robson, Esme Sutherland and Kohli, Pushmeet and de Freitas, Nando and Kavukcuoglu, Koray and Vinyals, Oriol},
	month = dec,
	year = {2022},
	note = {arXiv:2203.07814 [cs]},
	keywords = {Computer Science - Artificial Intelligence, Computer Science - Machine Learning, Computer Science - Programming Languages},
	pages = {1092--1097},
	file = {2203.07814.pdf:files/167/2203.07814.pdf:application/pdf},
}

@article{chaudhuri_neurosymbolic_2021,
	title = {Neurosymbolic {Programming}},
	volume = {7},
	issn = {2325-1107, 2325-1131},
	url = {http://www.nowpublishers.com/article/Details/PGL-049},
	doi = {10.1561/2500000049},
	abstract = {We survey recent work on neurosymbolic programming, an emerging area that bridges the areas of deep learning and program synthesis. Like in classic machine learning, the goal here is to learn functions from data. However, these functions are represented as programs that can use neural modules in addition to symbolic primitives and are induced using a combination of symbolic search and gradient-based optimization.},
	language = {en},
	number = {3},
	urldate = {2024-01-31},
	journal = {Foundations and Trends® in Programming Languages},
	author = {Chaudhuri, Swarat and Ellis, Kevin and Polozov, Oleksandr and Singh, Rishabh and Solar-Lezama, Armando and Yue, Yisong},
	year = {2021},
	pages = {158--243},
	file = {PGL-049-Plain (2).pdf:files/168/PGL-049-Plain (2).pdf:application/pdf},
}

@article{feenstra_globalization_nodate,
	title = {Globalization and {Its} {Impact} on {Labour}},
	language = {en},
	author = {Feenstra, Robert C},
	file = {wiiw-wp-044.pdf:files/169/wiiw-wp-044.pdf:application/pdf},
}

@book{kozen_automata_1977,
	address = {Berlin, Heidelberg},
	title = {Automata and {Computability}},
	isbn = {978-3-642-85708-9 978-3-642-85706-5},
	url = {http://link.springer.com/10.1007/978-3-642-85706-5},
	language = {en},
	urldate = {2024-01-31},
	publisher = {Springer Berlin Heidelberg},
	author = {Kozen, Dexter C.},
	year = {1977},
	doi = {10.1007/978-3-642-85706-5},
	file = {(Undergraduate Texts in Computer Science) Dexter C. Kozen - Automata and Computability-Springer (1977).pdf:files/170/(Undergraduate Texts in Computer Science) Dexter C. Kozen - Automata and Computability-Springer (1977).pdf:application/pdf},
}

@book{chlipala_certified_2013,
	address = {Cambridge, MA},
	title = {Certified programming with dependent types: a pragmatic introduction to the {Coq} proof assistant},
	isbn = {978-0-262-02665-9 978-0-262-54574-7},
	shorttitle = {Certified programming with dependent types},
	language = {en},
	publisher = {The MIT Press},
	author = {Chlipala, Adam},
	year = {2013},
	keywords = {Automatic theorem proving, Computer programming, Computer programs, Coq (Electronic resource)},
	file = {book_9780262317870.pdf:files/171/book_9780262317870.pdf:application/pdf},
}

@inproceedings{fu_inverse_2023,
	address = {Singapore},
	title = {Inverse {Reinforcement} {Learning} for {Text} {Summarization}},
	url = {https://aclanthology.org/2023.findings-emnlp.436},
	doi = {10.18653/v1/2023.findings-emnlp.436},
	abstract = {We introduce inverse reinforcement learning (IRL) as an effective paradigm for training abstractive summarization models, imitating human summarization behaviors. Our IRL model estimates the reward function using a suite of important sub-rewards for summarization and concurrently optimizes the policy network. Experimental results across datasets in different domains (CNN/DailyMail and WikiHow) and various model sizes (BART-base and BARTlarge) demonstrate the superiority of our proposed IRL model for summarization over MLE and RL baselines. The resulting summaries exhibit greater similarity to human-crafted gold references, outperforming MLE and RL baselines on metrics such as ROUGE, coverage, novelty, compression ratio, factuality, and human evaluations.},
	language = {en},
	urldate = {2024-01-31},
	booktitle = {Findings of the {Association} for {Computational} {Linguistics}: {EMNLP} 2023},
	publisher = {Association for Computational Linguistics},
	author = {Fu, Yu and Xiong, Deyi and Dong, Yue},
	year = {2023},
	pages = {6559--6570},
	file = {2023.findings-emnlp.436.pdf:files/172/2023.findings-emnlp.436.pdf:application/pdf},
}

@article{noauthor_theorem-proving_nodate,
	title = {Theorem-{Proving} on the {Computer}},
	language = {en},
	file = {321160.321166.pdf:files/175/321160.321166.pdf:application/pdf},
}

@article{noauthor_computing_nodate,
	title = {A {Computing} {Procedure} for {Quantification} {Theory}},
	language = {en},
	file = {321033.321034.pdf:files/177/321033.321034.pdf:application/pdf},
}

@article{davis_machine_nodate,
	title = {A {Machine} {Program} for {Theorem}-{Provingt}},
	language = {en},
	author = {Davis, Martin and Logemann, George and Loveland, Donald},
	file = {document (1).pdf:files/178/document (1).pdf:application/pdf},
}

@article{krizhevsky_imagenet_2017,
	title = {{ImageNet} classification with deep convolutional neural networks},
	volume = {60},
	issn = {0001-0782, 1557-7317},
	url = {https://dl.acm.org/doi/10.1145/3065386},
	doi = {10.1145/3065386},
	abstract = {We trained a large, deep convolutional neural network to classify the 1.2 million high-resolution images in the ImageNet LSVRC-2010 contest into the 1000 different classes. On the test data, we achieved top-1 and top-5 error rates of 37.5\% and 17.0\% which is considerably better than the previous state-of-the-art. The neural network, which has 60 million parameters and 650,000 neurons, consists of ﬁve convolutional layers, some of which are followed by max-pooling layers, and three fully-connected layers with a ﬁnal 1000-way softmax. To make training faster, we used non-saturating neurons and a very efﬁcient GPU implementation of the convolution operation. To reduce overﬁtting in the fully-connected layers we employed a recently-developed regularization method called “dropout” that proved to be very effective. We also entered a variant of this model in the ILSVRC-2012 competition and achieved a winning top-5 test error rate of 15.3\%, compared to 26.2\% achieved by the second-best entry.},
	language = {en},
	number = {6},
	urldate = {2024-01-31},
	journal = {Communications of the ACM},
	author = {Krizhevsky, Alex and Sutskever, Ilya and Hinton, Geoffrey E.},
	month = may,
	year = {2017},
	pages = {84--90},
	file = {NIPS-2012-imagenet-classification-with-deep-convolutional-neural-networks-Paper.pdf:files/179/NIPS-2012-imagenet-classification-with-deep-convolutional-neural-networks-Paper.pdf:application/pdf},
}

@misc{anthony_thinking_2017,
	title = {Thinking {Fast} and {Slow} with {Deep} {Learning} and {Tree} {Search}},
	url = {http://arxiv.org/abs/1705.08439},
	abstract = {Sequential decision making problems, such as structured prediction, robotic control, and game playing, require a combination of planning policies and generalisation of those plans. In this paper, we present Expert Iteration (EXIT), a novel reinforcement learning algorithm which decomposes the problem into separate planning and generalisation tasks. Planning new policies is performed by tree search, while a deep neural network generalises those plans. Subsequently, tree search is improved by using the neural network policy to guide search, increasing the strength of new plans. In contrast, standard deep Reinforcement Learning algorithms rely on a neural network not only to generalise plans, but to discover them too. We show that EXIT outperforms REINFORCE for training a neural network to play the board game Hex, and our ﬁnal tree search agent, trained tabula rasa, defeats MOHEX 1.0, the most recent Olympiad Champion player to be publicly released.},
	language = {en},
	urldate = {2024-01-31},
	publisher = {arXiv},
	author = {Anthony, Thomas and Tian, Zheng and Barber, David},
	month = dec,
	year = {2017},
	note = {arXiv:1705.08439 [cs]},
	keywords = {Computer Science - Artificial Intelligence},
	file = {1705.08439.pdf:files/180/1705.08439.pdf:application/pdf},
}

@misc{bansal_holist_2019,
	title = {{HOList}: {An} {Environment} for {Machine} {Learning} of {Higher}-{Order} {Theorem} {Proving}},
	shorttitle = {{HOList}},
	url = {http://arxiv.org/abs/1904.03241},
	abstract = {We present an environment, benchmark, and deep learning driven automated theorem prover for higher-order logic. Higher-order interactive theorem provers enable the formalization of arbitrary mathematical theories and thereby present an interesting, open-ended challenge for deep learning. We provide an open-source framework based on the HOL Light theorem prover that can be used as a reinforcement learning environment. HOL Light comes with a broad coverage of basic mathematical theorems on calculus and the formal proof of the Kepler conjecture, from which we derive a challenging benchmark for automated reasoning. We also present a deep reinforcement learning driven automated theorem prover, DeepHOL, with strong initial results on this benchmark.},
	language = {en},
	urldate = {2024-01-31},
	publisher = {arXiv},
	author = {Bansal, Kshitij and Loos, Sarah M. and Rabe, Markus N. and Szegedy, Christian and Wilcox, Stewart},
	month = nov,
	year = {2019},
	note = {arXiv:1904.03241 [cs]},
	keywords = {Computer Science - Artificial Intelligence, Computer Science - Logic in Computer Science, Computer Science - Machine Learning},
	file = {1904.03241.pdf:files/181/1904.03241.pdf:application/pdf},
}

@inproceedings{bengio_curriculum_2009,
	address = {Montreal Quebec Canada},
	title = {Curriculum learning},
	isbn = {978-1-60558-516-1},
	url = {https://dl.acm.org/doi/10.1145/1553374.1553380},
	doi = {10.1145/1553374.1553380},
	abstract = {Humans and animals learn much better when the examples are not randomly presented but organized in a meaningful order which illustrates gradually more concepts, and gradually more complex ones. Here, we formalize such training strategies in the context of machine learning, and call them “curriculum learning”. In the context of recent research studying the diﬃculty of training in the presence of non-convex training criteria (for deep deterministic and stochastic neural networks), we explore curriculum learning in various set-ups. The experiments show that signiﬁcant improvements in generalization can be achieved. We hypothesize that curriculum learning has both an eﬀect on the speed of convergence of the training process to a minimum and, in the case of non-convex criteria, on the quality of the local minima obtained: curriculum learning can be seen as a particular form of continuation method (a general strategy for global optimization of non-convex functions).},
	language = {en},
	urldate = {2024-01-31},
	booktitle = {Proceedings of the 26th {Annual} {International} {Conference} on {Machine} {Learning}},
	publisher = {ACM},
	author = {Bengio, Yoshua and Louradour, Jérôme and Collobert, Ronan and Weston, Jason},
	month = jun,
	year = {2009},
	pages = {41--48},
	file = {2009_curriculum_icml.pdf:files/182/2009_curriculum_icml.pdf:application/pdf},
}

@misc{cho_properties_2014,
	title = {On the {Properties} of {Neural} {Machine} {Translation}: {Encoder}-{Decoder} {Approaches}},
	shorttitle = {On the {Properties} of {Neural} {Machine} {Translation}},
	url = {http://arxiv.org/abs/1409.1259},
	abstract = {Neural machine translation is a relatively new approach to statistical machine translation based purely on neural networks. The neural machine translation models often consist of an encoder and a decoder. The encoder extracts a ﬁxed-length representation from a variable-length input sentence, and the decoder generates a correct translation from this representation. In this paper, we focus on analyzing the properties of the neural machine translation using two models; RNN Encoder–Decoder and a newly proposed gated recursive convolutional neural network. We show that the neural machine translation performs relatively well on short sentences without unknown words, but its performance degrades rapidly as the length of the sentence and the number of unknown words increase. Furthermore, we ﬁnd that the proposed gated recursive convolutional network learns a grammatical structure of a sentence automatically.},
	language = {en},
	urldate = {2024-01-31},
	publisher = {arXiv},
	author = {Cho, Kyunghyun and van Merrienboer, Bart and Bahdanau, Dzmitry and Bengio, Yoshua},
	month = oct,
	year = {2014},
	note = {arXiv:1409.1259 [cs, stat]},
	keywords = {Computer Science - Computation and Language, Statistics - Machine Learning},
	file = {1409.1259.pdf:files/183/1409.1259.pdf:application/pdf},
}

@book{russell_artificial_2022,
	address = {Harlow},
	edition = {Fourth edition, global edition},
	series = {Pearson series in artificial intelligence},
	title = {Artificial intelligence: a modern approach},
	isbn = {978-1-292-40113-3},
	shorttitle = {Artificial intelligence},
	abstract = {"Updated edition of popular textbook on Artificial Intelligence. This edition specific looks at ways of keeping artificial intelligence under control"},
	language = {en},
	publisher = {Pearson},
	author = {Russell, Stuart J. and Norvig, Peter and Chang, Ming-wei and Devlin, Jacob and Dragan, Anca and Forsyth, David and Goodfellow, Ian and Malik, Jitendra and Mansinghka, Vikas and Pearl, Judea and Wooldridge, Michael J.},
	year = {2022},
	file = {Stuart J. Russell, Peter Norvig - Artificial Intelligence_ A Modern Approach, Global Edition-Pearson (2021) (3).pdf:files/184/Stuart J. Russell, Peter Norvig - Artificial Intelligence_ A Modern Approach, Global Edition-Pearson (2021) (3).pdf:application/pdf},
}

@article{colton_notion_2000,
	title = {On the notion of interestingness in automated mathematical discovery},
	volume = {53},
	issn = {10715819},
	url = {https://linkinghub.elsevier.com/retrieve/pii/S107158190090394X},
	doi = {10.1006/ijhc.2000.0394},
	abstract = {We survey ﬁve mathematical discovery programs by looking in detail at the discovery processes they illustrate and the success they’ve had. We focus on how they estimate the interestingness of concepts and conjectures and extract some common notions about interestingness in automated mathematical discovery. We detail how empirical evidence is used to give plausibility to conjectures, and the diﬀerent ways in which a result can be thought of as novel. We also look at the ways in which the programs assess how surprising and complex a conjecture statement is, and the diﬀerent ways in which the applicability of a concept or conjecture is used. Finally, we note how a user can set tasks for the program to achieve and how this aﬀects the calculation of interestingness. We conclude with some hints on the use of interestingness measures for future developers of discovery programs in mathematics.},
	language = {en},
	number = {3},
	urldate = {2024-01-31},
	journal = {International Journal of Human-Computer Studies},
	author = {Colton, Simon and Bundy, Alan and Walsh, Toby},
	month = sep,
	year = {2000},
	pages = {351--375},
	file = {IJHCS00.pdf:files/185/IJHCS00.pdf:application/pdf},
}

@inproceedings{ellis_dreamcoder_2021,
	address = {Virtual Canada},
	title = {{DreamCoder}: bootstrapping inductive program synthesis with wake-sleep library learning},
	isbn = {978-1-4503-8391-2},
	shorttitle = {{DreamCoder}},
	url = {https://dl.acm.org/doi/10.1145/3453483.3454080},
	doi = {10.1145/3453483.3454080},
	abstract = {We present a system for inductive program synthesis called DreamCoder, which inputs a corpus of synthesis problems each specified by one or a few examples, and automatically derives a library of program components and a neural search policy that can be used to efficiently solve other similar synthesis problems. The library and search policy bootstrap each other iteratively through a variant of łwake-sleepž approximate Bayesian learning. A new refactoring algorithm based on E-graph matching identifies common sub-components across synthesized programs, building a progressively deepening library of abstractions capturing the structure of the input domain. We evaluate on eight domains including classic program synthesis areas and AI tasks such as planning, inverse graphics, and equation discovery. We show that jointly learning the library and neural search policy leads to solving more problems, and solving them more quickly.},
	language = {en},
	urldate = {2024-01-31},
	booktitle = {Proceedings of the 42nd {ACM} {SIGPLAN} {International} {Conference} on {Programming} {Language} {Design} and {Implementation}},
	publisher = {ACM},
	author = {Ellis, Kevin and Wong, Catherine and Nye, Maxwell and Sablé-Meyer, Mathias and Morales, Lucas and Hewitt, Luke and Cary, Luc and Solar-Lezama, Armando and Tenenbaum, Joshua B.},
	month = jun,
	year = {2021},
	pages = {835--850},
	file = {3453483.3454080 (1).pdf:files/186/3453483.3454080 (1).pdf:application/pdf},
}

@misc{huang_gamepad_2018,
	title = {{GamePad}: {A} {Learning} {Environment} for {Theorem} {Proving}},
	shorttitle = {{GamePad}},
	url = {http://arxiv.org/abs/1806.00608},
	abstract = {In this paper, we introduce a system called GamePad that can be used to explore the application of machine learning methods to theorem proving in the Coq proof assistant. Interactive theorem provers such as Coq enable users to construct machine-checkable proofs in a step-by-step manner. Hence, they provide an opportunity to explore theorem proving with human supervision. We use GamePad to synthesize proofs for a simple algebraic rewrite problem and train baseline models for a formalization of the Feit-Thompson theorem. We address position evaluation (i.e., predict the number of proof steps left) and tactic prediction (i.e., predict the next proof step) tasks, which arise naturally in tactic-based theorem proving.},
	language = {en},
	urldate = {2024-01-31},
	publisher = {arXiv},
	author = {Huang, Daniel and Dhariwal, Prafulla and Song, Dawn and Sutskever, Ilya},
	month = dec,
	year = {2018},
	note = {arXiv:1806.00608 [cs, stat]},
	keywords = {Computer Science - Artificial Intelligence, Computer Science - Logic in Computer Science, Computer Science - Machine Learning, Statistics - Machine Learning},
	file = {1806.00608.pdf:files/188/1806.00608.pdf:application/pdf},
}

@misc{alemi_deepmath_2017,
	title = {{DeepMath} - {Deep} {Sequence} {Models} for {Premise} {Selection}},
	url = {http://arxiv.org/abs/1606.04442},
	abstract = {We study the effectiveness of neural sequence models for premise selection in automated theorem proving, one of the main bottlenecks in the formalization of mathematics. We propose a two stage approach for this task that yields good results for the premise selection task on the Mizar corpus while avoiding the handengineered features of existing state-of-the-art models. To our knowledge, this is the ﬁrst time deep learning has been applied to theorem proving on a large scale.},
	language = {en},
	urldate = {2024-01-31},
	publisher = {arXiv},
	author = {Alemi, Alex A. and Chollet, Francois and Een, Niklas and Irving, Geoffrey and Szegedy, Christian and Urban, Josef},
	month = jan,
	year = {2017},
	note = {arXiv:1606.04442 [cs]},
	keywords = {Computer Science - Artificial Intelligence, Computer Science - Logic in Computer Science, Computer Science - Machine Learning},
	file = {1606.04442.pdf:files/189/1606.04442.pdf:application/pdf},
}

@misc{kaliszyk_reinforcement_2018,
	title = {Reinforcement {Learning} of {Theorem} {Proving}},
	url = {http://arxiv.org/abs/1805.07563},
	abstract = {We introduce a theorem proving algorithm that uses practically no domain heuristics for guiding its connection-style proof search. Instead, it runs many MonteCarlo simulations guided by reinforcement learning from previous proof attempts. We produce several versions of the prover, parameterized by different learning and guiding algorithms. The strongest version of the system is trained on a large corpus of mathematical problems and evaluated on previously unseen problems. The trained system solves within the same number of inferences over 40\% more problems than a baseline prover, which is an unusually high improvement in this hard AI domain. To our knowledge this is the ﬁrst time reinforcement learning has been convincingly applied to solving general mathematical problems on a large scale.},
	language = {en},
	urldate = {2024-01-31},
	publisher = {arXiv},
	author = {Kaliszyk, Cezary and Urban, Josef and Michalewski, Henryk and Olšák, Mirek},
	month = may,
	year = {2018},
	note = {arXiv:1805.07563 [cs]},
	keywords = {Computer Science - Artificial Intelligence, Computer Science - Logic in Computer Science, Computer Science - Machine Learning},
	file = {1805.07563.pdf:files/190/1805.07563.pdf:application/pdf},
}

@incollection{carbonell_elf_1994,
	address = {Berlin, Heidelberg},
	title = {Elf: {A} meta-language for deductive systems: {System} description},
	volume = {814},
	isbn = {978-3-540-58156-7 978-3-540-48467-7},
	shorttitle = {Elf},
	url = {http://link.springer.com/10.1007/3-540-58156-1_66},
	language = {en},
	urldate = {2024-01-31},
	booktitle = {Automated {Deduction} — {CADE}-12},
	publisher = {Springer Berlin Heidelberg},
	author = {Pfenning, Frank},
	editor = {Carbonell, J. G. and Siekmann, J. and Goos, G. and Hartmanis, J. and Bundy, Alan},
	year = {1994},
	doi = {10.1007/3-540-58156-1_66},
	note = {Series Title: Lecture Notes in Computer Science},
	pages = {811--815},
	file = {cade94.pdf:files/191/cade94.pdf:application/pdf},
}

@article{silver_general_2018,
	title = {A general reinforcement learning algorithm that masters chess, shogi, and {Go} through self-play},
	volume = {362},
	issn = {0036-8075, 1095-9203},
	url = {https://www.science.org/doi/10.1126/science.aar6404},
	doi = {10.1126/science.aar6404},
	abstract = {One program to rule them all
            
              Computers can beat humans at increasingly complex games, including chess and Go. However, these programs are typically constructed for a particular game, exploiting its properties, such as the symmetries of the board on which it is played. Silver
              et al.
              developed a program called AlphaZero, which taught itself to play Go, chess, and shogi (a Japanese version of chess) (see the Editorial, and the Perspective by Campbell). AlphaZero managed to beat state-of-the-art programs specializing in these three games. The ability of AlphaZero to adapt to various game rules is a notable step toward achieving a general game-playing system.
            
            
              Science
              , this issue p.
              1140
              ; see also pp.
              1087
              and
              1118
            
          , 
            AlphaZero teaches itself to play three different board games and beats state-of-the-art programs in each.
          , 
            The game of chess is the longest-studied domain in the history of artificial intelligence. The strongest programs are based on a combination of sophisticated search techniques, domain-specific adaptations, and handcrafted evaluation functions that have been refined by human experts over several decades. By contrast, the AlphaGo Zero program recently achieved superhuman performance in the game of Go by reinforcement learning from self-play. In this paper, we generalize this approach into a single AlphaZero algorithm that can achieve superhuman performance in many challenging games. Starting from random play and given no domain knowledge except the game rules, AlphaZero convincingly defeated a world champion program in the games of chess and shogi (Japanese chess), as well as Go.},
	language = {en},
	number = {6419},
	urldate = {2024-01-31},
	journal = {Science},
	author = {Silver, David and Hubert, Thomas and Schrittwieser, Julian and Antonoglou, Ioannis and Lai, Matthew and Guez, Arthur and Lanctot, Marc and Sifre, Laurent and Kumaran, Dharshan and Graepel, Thore and Lillicrap, Timothy and Simonyan, Karen and Hassabis, Demis},
	month = dec,
	year = {2018},
	pages = {1140--1144},
	file = {science.aar6404.pdf:files/193/science.aar6404.pdf:application/pdf},
}

@book{tomasello_cultural_1999,
	address = {Cambridge, Mass},
	title = {The cultural origins of human cognition},
	isbn = {978-0-674-00070-4},
	language = {en},
	publisher = {Harvard University Press},
	author = {Tomasello, Michael},
	year = {1999},
	keywords = {Cognition and culture, Cognition in children},
	file = {tomasello-the-cultural-origins-of-human-cognition.pdf:files/194/tomasello-the-cultural-origins-of-human-cognition.pdf:application/pdf},
}

@misc{whalen_holophrasm_2016,
	title = {Holophrasm: a neural {Automated} {Theorem} {Prover} for higher-order logic},
	shorttitle = {Holophrasm},
	url = {http://arxiv.org/abs/1608.02644},
	abstract = {I propose a system for Automated Theorem Proving in higher order logic using deep learning and eschewing hand-constructed features. Holophrasm exploits the formalism of the Metamath language and explores partial proof trees using a neural-network-augmented bandit algorithm and a sequence-to-sequence model for action enumeration. The system proves 14\% of its test theorems from Metamath’s set.mm module.},
	language = {en},
	urldate = {2024-01-31},
	publisher = {arXiv},
	author = {Whalen, Daniel},
	month = aug,
	year = {2016},
	note = {arXiv:1608.02644 [cs]},
	keywords = {Computer Science - Artificial Intelligence, Computer Science - Logic in Computer Science},
	file = {1608.02644.pdf:files/195/1608.02644.pdf:application/pdf},
}

@misc{wu_tacticzero_2021,
	title = {{TacticZero}: {Learning} to {Prove} {Theorems} from {Scratch} with {Deep} {Reinforcement} {Learning}},
	shorttitle = {{TacticZero}},
	url = {http://arxiv.org/abs/2102.09756},
	abstract = {We propose a novel approach to interactive theorem-proving (ITP) using deep reinforcement learning. The proposed framework is able to learn proof search strategies as well as tactic and arguments prediction in an end-to-end manner. We formulate the process of ITP as a Markov decision process (MDP) in which each state represents a set of potential derivation paths. This structure allows us to introduce a novel backtracking mechanism which enables the agent to efﬁciently discard (predicted) dead-end derivations and restart from promising alternatives. We implement the framework in the HOL4 theorem prover. Experimental results show that the framework outperforms existing automated theorem provers (i.e. hammers) available in HOL4 when evaluated on unseen problems. We further elaborate the role of key components of the framework using ablation studies.},
	language = {en},
	urldate = {2024-01-31},
	publisher = {arXiv},
	author = {Wu, Minchao and Norrish, Michael and Walder, Christian and Dezfouli, Amir},
	month = jun,
	year = {2021},
	note = {arXiv:2102.09756 [cs]},
	keywords = {Computer Science - Artificial Intelligence, Computer Science - Logic in Computer Science, Computer Science - Machine Learning},
	file = {2102.09756.pdf:files/196/2102.09756.pdf:application/pdf},
}

@article{noauthor_theorem-proving_nodate-1,
	title = {Theorem-{Proving} on the {Computer}},
	language = {en},
	file = {321160.321166 (1).pdf:files/198/321160.321166 (1).pdf:application/pdf},
}

@misc{sheth_neurosymbolic_2023,
	title = {Neurosymbolic {AI} -- {Why}, {What}, and {How}},
	url = {http://arxiv.org/abs/2305.00813},
	abstract = {Humans interact with the environment using a combination of perception - transforming sensory inputs from their environment into symbols, and cognition - mapping symbols to knowledge about the environment for supporting abstraction, reasoning by analogy, and long-term planning. Human perception-inspired machine perception, in the context of AI, refers to large-scale pattern recognition from raw data using neural networks trained using self-supervised learning objectives such as next-word prediction or object recognition. On the other hand, machine cognition encompasses more complex computations, such as using knowledge of the environment to guide reasoning, analogy, and long-term planning. Humans can also control and explain their cognitive functions. This seems to require the retention of symbolic mappings from perception outputs to knowledge about their environment. For example, humans can follow and explain the guidelines and safety constraints driving their decision-making in safety-critical applications such as healthcare, criminal justice, and autonomous driving. While datadriven neural network-based AI algorithms effectively model machine perception, symbolic knowledge-based AI is better suited for modeling machine cognition. This is because symbolic knowledge structures support explicit representations of mappings from perception outputs to the knowledge, enabling traceability and auditing of the AI system’s decisions. Such audit trails are useful for enforcing application aspects of safety, such as regulatory compliance and explainability, through tracking the AI system’s inputs, outputs, and intermediate steps. This ﬁrst article in the Neurosymbolic AI department introduces and provides an overview of the rapidly emerging paradigm of Neurosymbolic AI, combining neural networks and knowledge-guided symbolic approaches to create more capable and ﬂexible AI systems. These systems have immense potential to advance both algorithm-level (e.g., abstraction, analogy, reasoning) and application-level (e.g., explainable and safety-constrained decision-making) capabilities of AI systems.},
	language = {en},
	urldate = {2024-01-31},
	publisher = {arXiv},
	author = {Sheth, Amit and Roy, Kaushik and Gaur, Manas},
	month = may,
	year = {2023},
	note = {arXiv:2305.00813 [cs]},
	keywords = {Computer Science - Artificial Intelligence},
	file = {2305.00813.pdf:files/199/2305.00813.pdf:application/pdf},
}

@misc{bubeck_sparks_2023,
	title = {Sparks of {Artificial} {General} {Intelligence}: {Early} experiments with {GPT}-4},
	shorttitle = {Sparks of {Artificial} {General} {Intelligence}},
	url = {http://arxiv.org/abs/2303.12712},
	abstract = {Artiﬁcial intelligence (AI) researchers have been developing and reﬁning large language models (LLMs) that exhibit remarkable capabilities across a variety of domains and tasks, challenging our understanding of learning and cognition. The latest model developed by OpenAI, GPT-4 [Ope23], was trained using an unprecedented scale of compute and data. In this paper, we report on our investigation of an early version of GPT-4, when it was still in active development by OpenAI. We contend that (this early version of) GPT4 is part of a new cohort of LLMs (along with ChatGPT and Google’s PaLM for example) that exhibit more general intelligence than previous AI models. We discuss the rising capabilities and implications of these models. We demonstrate that, beyond its mastery of language, GPT-4 can solve novel and diﬃcult tasks that span mathematics, coding, vision, medicine, law, psychology and more, without needing any special prompting. Moreover, in all of these tasks, GPT-4’s performance is strikingly close to human-level performance, and often vastly surpasses prior models such as ChatGPT. Given the breadth and depth of GPT-4’s capabilities, we believe that it could reasonably be viewed as an early (yet still incomplete) version of an artiﬁcial general intelligence (AGI) system. In our exploration of GPT-4, we put special emphasis on discovering its limitations, and we discuss the challenges ahead for advancing towards deeper and more comprehensive versions of AGI, including the possible need for pursuing a new paradigm that moves beyond next-word prediction. We conclude with reﬂections on societal inﬂuences of the recent technological leap and future research directions.},
	language = {en},
	urldate = {2024-01-31},
	publisher = {arXiv},
	author = {Bubeck, Sébastien and Chandrasekaran, Varun and Eldan, Ronen and Gehrke, Johannes and Horvitz, Eric and Kamar, Ece and Lee, Peter and Lee, Yin Tat and Li, Yuanzhi and Lundberg, Scott and Nori, Harsha and Palangi, Hamid and Ribeiro, Marco Tulio and Zhang, Yi},
	month = apr,
	year = {2023},
	note = {arXiv:2303.12712 [cs]},
	keywords = {Computer Science - Artificial Intelligence, Computer Science - Computation and Language},
	file = {2303.12712.pdf:files/200/2303.12712.pdf:application/pdf},
}

@misc{hafner_mastering_2023,
	title = {Mastering {Diverse} {Domains} through {World} {Models}},
	url = {http://arxiv.org/abs/2301.04104},
	abstract = {General intelligence requires solving tasks across many domains. Current reinforcement learning algorithms carry this potential but are held back by the resources and knowledge required to tune them for new tasks. We present DreamerV3, a general and scalable algorithm based on world models that outperforms previous approaches across a wide range of domains with ﬁxed hyperparameters. These domains include continuous and discrete actions, visual and low-dimensional inputs, 2D and 3D worlds, different data budgets, reward frequencies, and reward scales. We observe favorable scaling properties of DreamerV3, with larger models directly translating to higher data-efﬁciency and ﬁnal performance. Applied out of the box, DreamerV3 is the ﬁrst algorithm to collect diamonds in Minecraft from scratch without human data or curricula, a long-standing challenge in artiﬁcial intelligence. Our general algorithm makes reinforcement learning broadly applicable and allows scaling to hard decision making problems.},
	language = {en},
	urldate = {2024-01-31},
	publisher = {arXiv},
	author = {Hafner, Danijar and Pasukonis, Jurgis and Ba, Jimmy and Lillicrap, Timothy},
	month = jan,
	year = {2023},
	note = {arXiv:2301.04104 [cs, stat]},
	keywords = {Computer Science - Artificial Intelligence, Computer Science - Machine Learning, Statistics - Machine Learning},
	file = {2301.04104.pdf:files/201/2301.04104.pdf:application/pdf},
}

@inproceedings{pathak_curiosity-driven_2017,
	address = {Honolulu, HI, USA},
	title = {Curiosity-{Driven} {Exploration} by {Self}-{Supervised} {Prediction}},
	isbn = {978-1-5386-0733-6},
	url = {http://ieeexplore.ieee.org/document/8014804/},
	doi = {10.1109/CVPRW.2017.70},
	abstract = {In many real-world scenarios, rewards extrinsic to the agent are extremely sparse, or absent altogether. In such cases, curiosity can serve as an intrinsic reward signal to enable the agent to explore its environment and learn skills that might be useful later in its life. We formulate curiosity as the error in an agent’s ability to predict the consequence of its own actions in a visual feature space learned by a self-supervised inverse dynamics model. Our formulation scales to high-dimensional continuous state spaces like images, bypasses the difﬁculties of directly predicting pixels, and, critically, ignores the aspects of the environment that cannot affect the agent. The proposed approach is evaluated in two environments: VizDoom and Super Mario Bros. Three broad settings are investigated: 1) sparse extrinsic reward, where curiosity allows for far fewer interactions with the environment to reach the goal; 2) exploration with no extrinsic reward, where curiosity pushes the agent to explore more efﬁciently; and 3) generalization to unseen scenarios (e.g. new levels of the same game) where the knowledge gained from earlier experience helps the agent explore new places much faster than starting from scratch.},
	language = {en},
	urldate = {2024-01-31},
	booktitle = {2017 {IEEE} {Conference} on {Computer} {Vision} and {Pattern} {Recognition} {Workshops} ({CVPRW})},
	publisher = {IEEE},
	author = {Pathak, Deepak and Agrawal, Pulkit and Efros, Alexei A. and Darrell, Trevor},
	month = jul,
	year = {2017},
	pages = {488--489},
	file = {icml17.pdf:files/202/icml17.pdf:application/pdf},
}

@article{noauthor_homotopy_nodate,
	title = {Homotopy {Type} {Theory}: {Univalent} {Foundations} of {Mathematics}},
	language = {en},
	file = {hott-ebook-13-g2e736d1.pdf:files/203/hott-ebook-13-g2e736d1.pdf:application/pdf},
}

@article{avigad_lean_nodate,
	title = {The {Lean} {Reference} {Manual}},
	language = {en},
	author = {Avigad, Jeremy and Ebner, Gabriel and Ullrich, Sebastian},
	file = {lean_reference.pdf:files/205/lean_reference.pdf:application/pdf},
}

@article{wenzel_isabelle_nodate,
	title = {The {Isabelle} {System} {Manual}},
	language = {en},
	author = {Wenzel, Makarius},
	file = {system.pdf:files/206/system.pdf:application/pdf},
}

@misc{touvron_llama_2023,
	title = {Llama 2: {Open} {Foundation} and {Fine}-{Tuned} {Chat} {Models}},
	shorttitle = {Llama 2},
	url = {http://arxiv.org/abs/2307.09288},
	abstract = {In this work, we develop and release Llama 2, a collection of pretrained and fine-tuned large language models (LLMs) ranging in scale from 7 billion to 70 billion parameters. Our fine-tuned LLMs, called Llama 2-Chat, are optimized for dialogue use cases. Our models outperform open-source chat models on most benchmarks we tested, and based on our human evaluations for helpfulness and safety, may be a suitable substitute for closedsource models. We provide a detailed description of our approach to fine-tuning and safety improvements of Llama 2-Chat in order to enable the community to build on our work and contribute to the responsible development of LLMs.},
	language = {en},
	urldate = {2024-01-31},
	publisher = {arXiv},
	author = {Touvron, Hugo and Martin, Louis and Stone, Kevin and Albert, Peter and Almahairi, Amjad and Babaei, Yasmine and Bashlykov, Nikolay and Batra, Soumya and Bhargava, Prajjwal and Bhosale, Shruti and Bikel, Dan and Blecher, Lukas and Ferrer, Cristian Canton and Chen, Moya and Cucurull, Guillem and Esiobu, David and Fernandes, Jude and Fu, Jeremy and Fu, Wenyin and Fuller, Brian and Gao, Cynthia and Goswami, Vedanuj and Goyal, Naman and Hartshorn, Anthony and Hosseini, Saghar and Hou, Rui and Inan, Hakan and Kardas, Marcin and Kerkez, Viktor and Khabsa, Madian and Kloumann, Isabel and Korenev, Artem and Koura, Punit Singh and Lachaux, Marie-Anne and Lavril, Thibaut and Lee, Jenya and Liskovich, Diana and Lu, Yinghai and Mao, Yuning and Martinet, Xavier and Mihaylov, Todor and Mishra, Pushkar and Molybog, Igor and Nie, Yixin and Poulton, Andrew and Reizenstein, Jeremy and Rungta, Rashi and Saladi, Kalyan and Schelten, Alan and Silva, Ruan and Smith, Eric Michael and Subramanian, Ranjan and Tan, Xiaoqing Ellen and Tang, Binh and Taylor, Ross and Williams, Adina and Kuan, Jian Xiang and Xu, Puxin and Yan, Zheng and Zarov, Iliyan and Zhang, Yuchen and Fan, Angela and Kambadur, Melanie and Narang, Sharan and Rodriguez, Aurelien and Stojnic, Robert and Edunov, Sergey and Scialom, Thomas},
	month = jul,
	year = {2023},
	note = {arXiv:2307.09288 [cs]},
	keywords = {Computer Science - Artificial Intelligence, Computer Science - Computation and Language},
	file = {2307.09288.pdf:files/207/2307.09288.pdf:application/pdf},
}
